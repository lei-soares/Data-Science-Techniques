{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1945c7f8",
   "metadata": {},
   "source": [
    "# Classification Models Catalog\n",
    "\n",
    "Folder: `02_classification_models`\n",
    "\n",
    "This notebook documents **20 popular classification models**, including descriptions, hyperparameter tuning ranges (suitable for GridSearchCV), strengths, and weaknesses.\n",
    "\n",
    "Assumes a standard supervised setup with `X_train, X_test, y_train, y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfad318",
   "metadata": {},
   "source": [
    "- Model name\n",
    "\n",
    "- Description\n",
    "\n",
    "- Importing\n",
    "\n",
    "- Fitting\n",
    "\n",
    "- Hyperparameter tuning\n",
    "            \n",
    "        includes all commonly tuned parameters + practical value ranges for GridSearch\n",
    "\n",
    "- Strengths\n",
    "\n",
    "- Weaknesses\n",
    "\n",
    "The notebook assumes a standard supervised setup: `X_train, X_test, y_train, y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc70003",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "**Description:** Linear model for binary and multiclass classification using the logistic function.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- C: [0.01, 0.1, 1, 10, 100]\n",
    "- penalty: ['l1','l2','elasticnet']\n",
    "- solver: ['liblinear','saga']\n",
    "- class_weight: [None,'balanced']\n",
    "\n",
    "**Strengths:** Interpretable, fast, strong baseline\n",
    "\n",
    "**Weaknesses:** Linear decision boundary, sensitive to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0df8f0",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "**Description:** Instance-based classifier using majority vote of neighbors.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- n_neighbors: [3,5,7,11,15]\n",
    "- weights: ['uniform','distance']\n",
    "- p: [1,2]\n",
    "\n",
    "**Strengths:** Simple, non-parametric\n",
    "\n",
    "**Weaknesses:** Slow inference, sensitive to scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a8905",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "**Description:** Maximum-margin classifier with kernel trick.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- C: [0.1,1,10,100]\n",
    "- kernel: ['linear','rbf','poly']\n",
    "- gamma: ['scale','auto']\n",
    "\n",
    "**Strengths:** Effective in high dimensions\n",
    "\n",
    "**Weaknesses:** Poor scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab3493",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "**Description:** Tree-based model using recursive feature splits.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- max_depth: [None,5,10,20]\n",
    "- min_samples_split: [2,5,10]\n",
    "- min_samples_leaf: [1,2,5]\n",
    "\n",
    "**Strengths:** Easy to interpret, non-linear\n",
    "\n",
    "**Weaknesses:** Prone to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abad19e",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "**Description:** Ensemble of decision trees using bagging.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- n_estimators: [100,300,500]\n",
    "- max_depth: [None,10,30]\n",
    "- max_features: ['sqrt','log2']\n",
    "\n",
    "**Strengths:** Robust, strong generalization\n",
    "\n",
    "**Weaknesses:** Less interpretable, heavy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e956f2",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "**Description:** Sequential boosting of weak learners.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- n_estimators: [100,300]\n",
    "- learning_rate: [0.01,0.1]\n",
    "- max_depth: [3,5]\n",
    "\n",
    "**Strengths:** High accuracy\n",
    "\n",
    "**Weaknesses:** Sensitive to tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8f201",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "**Description:** Optimized gradient boosting with regularization.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from xgboost import XGBClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = XGBClassifier(eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- n_estimators: [300,600]\n",
    "- learning_rate: [0.01,0.1]\n",
    "- max_depth: [3,6]\n",
    "- subsample: [0.7,1.0]\n",
    "\n",
    "**Strengths:** State-of-the-art performance\n",
    "\n",
    "**Weaknesses:** Complex tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44835ce",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "\n",
    "**Description:** Histogram-based gradient boosting.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from lightgbm import LGBMClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- num_leaves: [31,63]\n",
    "- learning_rate: [0.01,0.1]\n",
    "- n_estimators: [300,600]\n",
    "\n",
    "**Strengths:** Very fast, scalable\n",
    "\n",
    "**Weaknesses:** Can overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb696f3",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "\n",
    "**Description:** Boosting with native categorical handling.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from catboost import CatBoostClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = CatBoostClassifier(verbose=0)\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- iterations: [300,600]\n",
    "- depth: [4,6,8]\n",
    "- learning_rate: [0.01,0.1]\n",
    "\n",
    "**Strengths:** Minimal preprocessing\n",
    "\n",
    "**Weaknesses:** Slower training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fdf414",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "**Description:** Probabilistic classifier based on Bayes theorem.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- var_smoothing: [1e-9,1e-8,1e-7]\n",
    "\n",
    "**Strengths:** Very fast, works with small data\n",
    "\n",
    "**Weaknesses:** Strong independence assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da22b58",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis\n",
    "\n",
    "**Description:** Linear classifier maximizing class separation.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- solver: ['svd','lsqr','eigen']\n",
    "\n",
    "**Strengths:** Strong for normally distributed data\n",
    "\n",
    "**Weaknesses:** Assumes Gaussian classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7158df",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis\n",
    "\n",
    "**Description:** Quadratic decision boundary classifier.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- reg_param: [0,0.1,0.5]\n",
    "\n",
    "**Strengths:** Flexible boundaries\n",
    "\n",
    "**Weaknesses:** Sensitive to small samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288f57c",
   "metadata": {},
   "source": [
    "## Extra Trees\n",
    "\n",
    "**Description:** Extremely randomized tree ensemble.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = ExtraTreesClassifier(n_estimators=300)\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- n_estimators: [200,500]\n",
    "- max_depth: [None,20]\n",
    "- max_features: ['sqrt','log2']\n",
    "\n",
    "**Strengths:** Low variance, fast\n",
    "\n",
    "**Weaknesses:** Low interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ffb258",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "**Description:** Boosting focusing on hard samples.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- n_estimators: [100,300]\n",
    "- learning_rate: [0.01,0.1,1]\n",
    "\n",
    "**Strengths:** Improves weak learners\n",
    "\n",
    "**Weaknesses:** Sensitive to noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c2e71",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "**Description:** Online linear classifier.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.linear_model import Perceptron\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = Perceptron()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- alpha: [1e-4,1e-3]\n",
    "- max_iter: [1000,3000]\n",
    "\n",
    "**Strengths:** Very fast\n",
    "\n",
    "**Weaknesses:** Only linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920bc5f0",
   "metadata": {},
   "source": [
    "## Passive Aggressive\n",
    "\n",
    "**Description:** Online margin-based classifier.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = PassiveAggressiveClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- C: [0.01,0.1,1,10]\n",
    "- max_iter: [1000,3000]\n",
    "\n",
    "**Strengths:** Fast, scalable\n",
    "\n",
    "**Weaknesses:** Sensitive to noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbdc613",
   "metadata": {},
   "source": [
    "## Ridge Classifier\n",
    "\n",
    "**Description:** Linear classifier with L2 regularization.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = RidgeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- alpha: [0.1,1,10]\n",
    "- class_weight: [None,'balanced']\n",
    "\n",
    "**Strengths:** Stable, fast\n",
    "\n",
    "**Weaknesses:** No probability outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa2709",
   "metadata": {},
   "source": [
    "## SGD Classifier\n",
    "\n",
    "**Description:** Stochastic gradient descent classifier.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- loss: ['hinge','log_loss']\n",
    "- alpha: [1e-4,1e-3]\n",
    "- max_iter: [1000,3000]\n",
    "\n",
    "**Strengths:** Highly scalable\n",
    "\n",
    "**Weaknesses:** Needs careful tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4e7ba",
   "metadata": {},
   "source": [
    "## Gaussian Process Classifier\n",
    "\n",
    "**Description:** Probabilistic non-parametric classifier.\n",
    "\n",
    "**Importing:**\n",
    "```python\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "```\n",
    "\n",
    "**Fitting:**\n",
    "```python\n",
    "model = GaussianProcessClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Hyperparameter Tuning (GridSearch):**\n",
    "- kernel: ['RBF','Matern']\n",
    "- max_iter_predict: [100,300]\n",
    "\n",
    "**Strengths:** Uncertainty estimation\n",
    "\n",
    "**Weaknesses:** Very slow, poor scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
