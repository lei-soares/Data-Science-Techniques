{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbeaba76-4018-4e26-8166-2abb9c1e23ab",
   "metadata": {},
   "source": [
    "# Hugging Face BERT for Text Classification\n",
    "## Objective\n",
    "\n",
    "Fine-tune a pre-trained BERT model for text classification using the Hugging Face ecosystem.\n",
    "\n",
    "Unlike previous notebooks:\n",
    "\n",
    "- Feature extraction is learned end-to-end\n",
    "- Tokenization becomes model-dependent\n",
    "> Leakage risks move to the tokenization + split boundary\n",
    "## Why End-to-End Transformers\n",
    "\n",
    "Compared to frozen embeddings (e.g. SBERT):\n",
    "\n",
    "- Representations adapt to the task\n",
    "- Contextual semantics are optimized\n",
    "- Higher performance ceiling\n",
    "\n",
    "Trade-offs:\n",
    "\n",
    "- More compute\n",
    "- Less interpretability\n",
    "- Greater tuning sensitivity\n",
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7610b8ae-e4a5-4610-a98f-4cb1e0d4949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77f73f-27f4-4b3c-a733-021f9f80de62",
   "metadata": {},
   "source": [
    "# Reproducibility Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aecc434d-3078-4d95-b22b-3fb1f3f5df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED =  2010\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d14d04-175c-48ab-ad55-98c57bc9a3fc",
   "metadata": {},
   "source": [
    "## Example Dataset\n",
    "Binary sentiment-style classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c52300e0-353c-4fee-b511-c2af750f544c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This model works very well</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent performance and stability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terrible results and poor accuracy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad predictions and unreliable output</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robust and interpretable system</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Awful behavior and weak model</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  label\n",
       "0             This model works very well      1\n",
       "1    Excellent performance and stability      1\n",
       "2     Terrible results and poor accuracy      0\n",
       "3  Bad predictions and unreliable output      0\n",
       "4        Robust and interpretable system      1\n",
       "5          Awful behavior and weak model      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"text\": [\n",
    "        \"This model works very well\",\n",
    "        \"Excellent performance and stability\",\n",
    "        \"Terrible results and poor accuracy\",\n",
    "        \"Bad predictions and unreliable output\",\n",
    "        \"Robust and interpretable system\",\n",
    "        \"Awful behavior and weak model\"\n",
    "    ],\n",
    "    \"label\": [1, 1, 0, 0, 1, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f01b27-fc3a-477c-b607-cd10952698df",
   "metadata": {},
   "source": [
    "# Train / Validation Split\n",
    "\n",
    "**Critical:** Split before tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a16126b3-82a7-448e-85f6-e916bdcf0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,\n",
    "    random_state=SEED,\n",
    "    stratify=df[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f240554-ca15-4943-88c6-00f44709a778",
   "metadata": {},
   "source": [
    "## Convert to Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97646705-1ff1-4dff-b5f3-64250e6bded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1e872-ceec-417a-802c-00f303b182a5",
   "metadata": {},
   "source": [
    "# Load Tokenizer and Model\n",
    "## Model Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dbaeee7-9a93-42a4-8fd3-d9c3375825b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "285f1cb6-8ee0-4686-bc22-55173181fa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b34feb0-8a61-4876-afc6-8d057ec424b9",
   "metadata": {},
   "source": [
    "## Tokenization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4b33c11-7953-4132-962f-df4c819f8077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d093599-5eaa-4e24-8d19-211add2e2e42",
   "metadata": {},
   "source": [
    "## Apply Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d88568-0227-4b68-bc5b-b37206a2d889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35505242712b4c7c98a265a776ec04f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c378f942ed40639b6d6214bc51045e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = train_ds.map(tokenize_batch, batched=True)\n",
    "val_ds = val_ds.map(tokenize_batch, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b046e-d5c0-4033-97b2-30f95a85dd18",
   "metadata": {},
   "source": [
    "## Set Dataset Format for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a959456-2b65-4555-aa86-f917690ff76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "\n",
    "train_ds.set_format(type=\"torch\", columns=columns)\n",
    "val_ds.set_format(type=\"torch\", columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d795971-27bd-49d9-b924-9231d419edf9",
   "metadata": {},
   "source": [
    "## Define Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f47c176a-41ee-4ecd-a562-ee8d64429a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6e4e6-251b-4979-ac95-13e598172998",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c02ed1-502d-45ce-8c4b-cbaae2655033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_results\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31d87af8-e8f9-46d9-8c54-7b6902ad122b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\pantu\\anaconda3\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pantu\\appdata\\roaming\\python\\python39\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ltk (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onda-verify (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onda-verify (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onda-verify (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\pantu\\anaconda3\\lib\\site-packages (4.57.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pantu\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ltk (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onda-verify (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onda-verify (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -onda-verify (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\users\\pantu\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Source - https://stackoverflow.com/a/76452964\n",
    "# Posted by alvas, modified by community. See post 'Timeline' for change history\n",
    "# Retrieved 2026-02-06, License - CC BY-SA 4.0\n",
    "\n",
    "! pip install -U accelerate\n",
    "! pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3331585-c032-44a0-a677-ec8c2821d21d",
   "metadata": {},
   "source": [
    "## Trainer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e291345-a016-404e-8b23-9e36afe2c2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pantu\\AppData\\Local\\Temp\\ipykernel_22136\\4015516837.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4a99e-065f-48f5-838a-2346b5bda8ed",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fae2c43a-1789-47ad-af67-962c640592c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pantu\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.669275</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.658616</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.649734</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pantu\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\pantu\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=0.6913228034973145, metrics={'train_runtime': 9.4453, 'train_samples_per_second': 1.27, 'train_steps_per_second': 0.318, 'total_flos': 789333166080.0, 'train_loss': 0.6913228034973145, 'epoch': 3.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc8537-a920-449a-b798-7d34c88db58a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "136a6667-c993-424c-aaf4-bb0eb0058956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pantu\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6692748069763184,\n",
       " 'eval_accuracy': 0.5,\n",
       " 'eval_f1': 0.6666666666666666,\n",
       " 'eval_runtime': 0.1651,\n",
       " 'eval_samples_per_second': 12.117,\n",
       " 'eval_steps_per_second': 6.059,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cadb224-f3d4-43b4-a49c-a0f947698208",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b606097-f87b-48e2-9007-499951cb67c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The model shows excellent performance\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2c0f1-7c16-468c-a426-547a4a930452",
   "metadata": {},
   "source": [
    "# Interpretation Notes\n",
    "\n",
    "- BERT learns task-specific representations\n",
    "- Attention â‰  explanation\n",
    "- Use probing or SHAP-style methods for insights\n",
    "# Common Mistakes\n",
    "\n",
    "- `[neg] -` Tokenizing before splitting\n",
    "- `[neg] -` Using excessive max_length\n",
    "- `[neg] -` Ignoring class imbalance\n",
    "- `[neg] -` Over-training small datasets\n",
    "\n",
    "# Key Takeaways\n",
    "\n",
    "- Transformers require strict pipeline discipline\n",
    "- Tokenization is part of the model\n",
    "- Fine-tuning yields strong gains\n",
    "- Baselines still matter for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3897281-979f-4432-9210-74c40e130fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e2041b-7ba9-433f-b9b1-1d8abeee9bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694fdfe-664a-4e5b-b4e2-f647841b7bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bbc45e-72bc-40ee-a8e9-dca82bbecd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b215965-5541-48f3-b5f6-9c863b60c679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
