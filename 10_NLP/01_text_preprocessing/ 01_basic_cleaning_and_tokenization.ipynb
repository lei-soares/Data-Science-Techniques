{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f08986-b11a-490f-ae3e-89e1f14a2bd7",
   "metadata": {},
   "source": [
    "# Basic Cleaning and Tokenization\n",
    "# Objective\n",
    "\n",
    "Convert raw, unstructured text into clean, well-defined tokens suitable for downstream NLP tasks such as:\n",
    "\n",
    "- Feature extraction (BoW, TF-IDF)\n",
    "\n",
    "- Embeddings\n",
    "\n",
    "- Classical ML or transformer models\n",
    "\n",
    "This notebook focuses on deterministic, reproducible preprocessing, not aggressive linguistic normalization.\n",
    "\n",
    "# Why This Step Matters\n",
    "\n",
    "Text preprocessing errors propagate silently and can cause:\n",
    "\n",
    "- Vocabulary explosion\n",
    "\n",
    "- Inconsistent feature spaces\n",
    "\n",
    "- Hidden data leakage\n",
    "\n",
    "- Poor generalization\n",
    "\n",
    "Tokenization defines what the model can and cannot learn.\n",
    "\n",
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7ddb3b-29f4-473b-9364-681a028f7963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pantu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f242529b-4ec2-4c0e-8da3-1098fba6b82d",
   "metadata": {},
   "source": [
    "# Example Dataset\n",
    "\n",
    "We deliberately use raw, messy text to reflect real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8fa84b7-cfae-4192-a75f-7fa2d4151c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is AMAZING!!! üòÉ Visit https://example.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP is hard... or is it? ü§î #datascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tokenization errors = silent model failures.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clean text ‚Üí better models.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  This is AMAZING!!! üòÉ Visit https://example.com...\n",
       "1            NLP is hard... or is it? ü§î #datascience\n",
       "2       Tokenization errors = silent model failures.\n",
       "3                        Clean text ‚Üí better models."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"text\": [\n",
    "        \"This is AMAZING!!! üòÉ Visit https://example.com now.\",\n",
    "        \"NLP is hard... or is it? ü§î #datascience\",\n",
    "        \"Tokenization errors = silent model failures.\",\n",
    "        \"Clean text ‚Üí better models.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a3f8a-0360-4f80-8c66-0106dc10dd3f",
   "metadata": {},
   "source": [
    "# Lowercasing\n",
    "Rationale\n",
    "\n",
    "- Reduces vocabulary size\n",
    "\n",
    "- Avoids case-sensitive duplicates (Model vs model)\n",
    "\n",
    "- Usually safe for English (be cautious with proper nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c55fac59-5514-4dbc-9a85-206ed5323c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is AMAZING!!! üòÉ Visit https://example.com...</td>\n",
       "      <td>this is amazing!!! üòÉ visit https://example.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP is hard... or is it? ü§î #datascience</td>\n",
       "      <td>nlp is hard... or is it? ü§î #datascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tokenization errors = silent model failures.</td>\n",
       "      <td>tokenization errors = silent model failures.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clean text ‚Üí better models.</td>\n",
       "      <td>clean text ‚Üí better models.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  This is AMAZING!!! üòÉ Visit https://example.com...   \n",
       "1            NLP is hard... or is it? ü§î #datascience   \n",
       "2       Tokenization errors = silent model failures.   \n",
       "3                        Clean text ‚Üí better models.   \n",
       "\n",
       "                                          text_lower  \n",
       "0  this is amazing!!! üòÉ visit https://example.com...  \n",
       "1            nlp is hard... or is it? ü§î #datascience  \n",
       "2       tokenization errors = silent model failures.  \n",
       "3                        clean text ‚Üí better models.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lowercase_text(text: str) -> str:\n",
    "    return text.lower()\n",
    "\n",
    "df[\"text_lower\"] = df[\"text\"].apply(lowercase_text)\n",
    "df[[\"text\", \"text_lower\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20facf1d-2a82-4cd8-bff6-9ff105dc4278",
   "metadata": {},
   "source": [
    "# Remove URLs\n",
    "Rationale\n",
    "\n",
    "- URLs rarely add semantic value for most NLP tasks\n",
    "\n",
    "- Often act as high-variance noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41fe3092-833f-4d6d-9275-b80167457f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_no_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is amazing!!! üòÉ visit https://example.com...</td>\n",
       "      <td>this is amazing!!! üòÉ visit  now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nlp is hard... or is it? ü§î #datascience</td>\n",
       "      <td>nlp is hard... or is it? ü§î #datascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tokenization errors = silent model failures.</td>\n",
       "      <td>tokenization errors = silent model failures.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean text ‚Üí better models.</td>\n",
       "      <td>clean text ‚Üí better models.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_lower  \\\n",
       "0  this is amazing!!! üòÉ visit https://example.com...   \n",
       "1            nlp is hard... or is it? ü§î #datascience   \n",
       "2       tokenization errors = silent model failures.   \n",
       "3                        clean text ‚Üí better models.   \n",
       "\n",
       "                                    text_no_url  \n",
       "0              this is amazing!!! üòÉ visit  now.  \n",
       "1       nlp is hard... or is it? ü§î #datascience  \n",
       "2  tokenization errors = silent model failures.  \n",
       "3                   clean text ‚Üí better models.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_PATTERN = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "\n",
    "def remove_urls(text: str) -> str:\n",
    "    return URL_PATTERN.sub(\"\", text)\n",
    "\n",
    "df[\"text_no_url\"] = df[\"text_lower\"].apply(remove_urls)\n",
    "df[[\"text_lower\", \"text_no_url\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f44b10-5888-4b40-8d76-7718f37c2720",
   "metadata": {},
   "source": [
    "# Remove Punctuation\n",
    "Rationale\n",
    "\n",
    "- Punctuation inflates token space\n",
    "\n",
    "- Exceptions exist (sentiment, legal text, code NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6ba18d1-71c5-4ad5-8ec4-293ca25171b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_no_url</th>\n",
       "      <th>text_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is amazing!!! üòÉ visit  now.</td>\n",
       "      <td>this is amazing üòÉ visit  now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nlp is hard... or is it? ü§î #datascience</td>\n",
       "      <td>nlp is hard or is it ü§î datascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tokenization errors = silent model failures.</td>\n",
       "      <td>tokenization errors  silent model failures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean text ‚Üí better models.</td>\n",
       "      <td>clean text ‚Üí better models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text_no_url  \\\n",
       "0              this is amazing!!! üòÉ visit  now.   \n",
       "1       nlp is hard... or is it? ü§î #datascience   \n",
       "2  tokenization errors = silent model failures.   \n",
       "3                   clean text ‚Üí better models.   \n",
       "\n",
       "                                text_no_punct  \n",
       "0                this is amazing üòÉ visit  now  \n",
       "1          nlp is hard or is it ü§î datascience  \n",
       "2  tokenization errors  silent model failures  \n",
       "3                  clean text ‚Üí better models  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PUNCT_TABLE = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "def remove_punctuation(text: str) -> str:\n",
    "    return text.translate(PUNCT_TABLE)\n",
    "\n",
    "df[\"text_no_punct\"] = df[\"text_no_url\"].apply(remove_punctuation)\n",
    "df[[\"text_no_url\", \"text_no_punct\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7898c3-d963-4e85-8e71-3264cc0c0696",
   "metadata": {},
   "source": [
    "# Remove Non-Alphabetic Characters (Optional)\n",
    "Rationale\n",
    "\n",
    "- Emojis, symbols, and numbers may be noise\n",
    "\n",
    "- Task-dependent decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6169186-fa39-4fea-b97b-9e20fe74485d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_no_punct</th>\n",
       "      <th>text_alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is amazing üòÉ visit  now</td>\n",
       "      <td>this is amazing  visit  now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nlp is hard or is it ü§î datascience</td>\n",
       "      <td>nlp is hard or is it  datascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tokenization errors  silent model failures</td>\n",
       "      <td>tokenization errors  silent model failures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean text ‚Üí better models</td>\n",
       "      <td>clean text  better models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text_no_punct  \\\n",
       "0                this is amazing üòÉ visit  now   \n",
       "1          nlp is hard or is it ü§î datascience   \n",
       "2  tokenization errors  silent model failures   \n",
       "3                  clean text ‚Üí better models   \n",
       "\n",
       "                                   text_alpha  \n",
       "0                 this is amazing  visit  now  \n",
       "1           nlp is hard or is it  datascience  \n",
       "2  tokenization errors  silent model failures  \n",
       "3                   clean text  better models  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_non_alpha(text: str) -> str:\n",
    "    return re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "df[\"text_alpha\"] = df[\"text_no_punct\"].apply(remove_non_alpha)\n",
    "df[[\"text_no_punct\", \"text_alpha\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee52d34-3b3e-4c03-84a9-fafe508876d4",
   "metadata": {},
   "source": [
    "# Tokenization (Word Level)\n",
    "Rationale\n",
    "\n",
    "- Converts cleaned text into model-usable units\n",
    "\n",
    "- Token definition affects every downstream step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b97ad10-c143-4063-b537-679a9a93b190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_alpha</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is amazing  visit  now</td>\n",
       "      <td>[this, is, amazing, visit, now]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nlp is hard or is it  datascience</td>\n",
       "      <td>[nlp, is, hard, or, is, it, datascience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tokenization errors  silent model failures</td>\n",
       "      <td>[tokenization, errors, silent, model, failures]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean text  better models</td>\n",
       "      <td>[clean, text, better, models]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text_alpha  \\\n",
       "0                 this is amazing  visit  now   \n",
       "1           nlp is hard or is it  datascience   \n",
       "2  tokenization errors  silent model failures   \n",
       "3                   clean text  better models   \n",
       "\n",
       "                                            tokens  \n",
       "0                  [this, is, amazing, visit, now]  \n",
       "1         [nlp, is, hard, or, is, it, datascience]  \n",
       "2  [tokenization, errors, silent, model, failures]  \n",
       "3                    [clean, text, better, models]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_words(text: str) -> List[str]:\n",
    "    return word_tokenize(text)\n",
    "\n",
    "df[\"tokens\"] = df[\"text_alpha\"].apply(tokenize_words)\n",
    "df[[\"text_alpha\", \"tokens\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d5fb4-c9b3-43bc-8c03-879a1f8af671",
   "metadata": {},
   "source": [
    "# Sentence Tokenization (Optional)\n",
    "\n",
    "Useful for:\n",
    "\n",
    "- Document segmentation\n",
    "\n",
    "- Summarization\n",
    "\n",
    "- Transformer chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddbb5ebc-b2ff-4cb8-8d77-e70081fa2aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is AMAZING!!! üòÉ Visit https://example.com...</td>\n",
       "      <td>[This is AMAZING!!!, üòÉ Visit https://example.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP is hard... or is it? ü§î #datascience</td>\n",
       "      <td>[NLP is hard... or is it?, ü§î #datascience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tokenization errors = silent model failures.</td>\n",
       "      <td>[Tokenization errors = silent model failures.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clean text ‚Üí better models.</td>\n",
       "      <td>[Clean text ‚Üí better models.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  This is AMAZING!!! üòÉ Visit https://example.com...   \n",
       "1            NLP is hard... or is it? ü§î #datascience   \n",
       "2       Tokenization errors = silent model failures.   \n",
       "3                        Clean text ‚Üí better models.   \n",
       "\n",
       "                                           sentences  \n",
       "0  [This is AMAZING!!!, üòÉ Visit https://example.c...  \n",
       "1         [NLP is hard... or is it?, ü§î #datascience]  \n",
       "2     [Tokenization errors = silent model failures.]  \n",
       "3                      [Clean text ‚Üí better models.]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentences\"] = df[\"text\"].apply(sent_tokenize)\n",
    "df[[\"text\", \"sentences\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a45bb-dec6-42c7-a886-a9003bc7ddee",
   "metadata": {},
   "source": [
    "# Common Tokenization Pitfalls\n",
    "\n",
    "- ‚ùå Tokenizing before cleaning\n",
    "- ‚ùå Mixing tokenization strategies across datasets\n",
    "- ‚ùå Fitting tokenizers on test data\n",
    "- ‚ùå Ignoring language-specific rules\n",
    "\n",
    "# Pipeline-Safe Design Pattern\n",
    "\n",
    "All preprocessing steps should be:\n",
    "\n",
    "- Deterministic\n",
    "\n",
    "- Stateless\n",
    "\n",
    "- Encapsulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67ceedbd-76e1-4003-9ea0-cf7a129c4753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens_pipeline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is AMAZING!!! üòÉ Visit https://example.com...</td>\n",
       "      <td>[this, is, amazing, visit, now]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP is hard... or is it? ü§î #datascience</td>\n",
       "      <td>[nlp, is, hard, or, is, it, datascience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tokenization errors = silent model failures.</td>\n",
       "      <td>[tokenization, errors, silent, model, failures]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clean text ‚Üí better models.</td>\n",
       "      <td>[clean, text, better, models]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  This is AMAZING!!! üòÉ Visit https://example.com...   \n",
       "1            NLP is hard... or is it? ü§î #datascience   \n",
       "2       Tokenization errors = silent model failures.   \n",
       "3                        Clean text ‚Üí better models.   \n",
       "\n",
       "                                   tokens_pipeline  \n",
       "0                  [this, is, amazing, visit, now]  \n",
       "1         [nlp, is, hard, or, is, it, datascience]  \n",
       "2  [tokenization, errors, silent, model, failures]  \n",
       "3                    [clean, text, better, models]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def basic_text_preprocessing(text: str) -> List[str]:\n",
    "    text = text.lower()\n",
    "    text = remove_urls(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_non_alpha(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "df[\"tokens_pipeline\"] = df[\"text\"].apply(basic_text_preprocessing)\n",
    "df[[\"text\", \"tokens_pipeline\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b241375-2085-4006-9be7-e5fcaeddb69a",
   "metadata": {},
   "source": [
    "# Key Takeaways\n",
    "\n",
    "- Tokenization defines your feature space\n",
    "\n",
    "- Simple cleaning beats aggressive heuristics\n",
    "\n",
    "- Always design preprocessing as a reusable pipeline\n",
    "\n",
    "- Never leak information via fitted tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57881554-00c0-4976-ab15-6d1e5fa73c12",
   "metadata": {},
   "source": [
    "# Next Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6ebe95-4518-4659-9215-380236025a64",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a9736c-2a01-4155-be05-0f958a238fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba9837-dedf-45b0-823c-e52e7e1dd99a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
