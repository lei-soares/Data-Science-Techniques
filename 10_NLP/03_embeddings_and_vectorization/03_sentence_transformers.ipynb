{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5745783a-3ea0-49f2-b9f6-0b2015098cc3",
   "metadata": {},
   "source": [
    "# Sentence Transformers (Sentence-BERT)\n",
    "## Objective\n",
    "\n",
    "Generate dense, semantically meaningful sentence and document embeddings using Sentence-BERT (SBERT), enabling:\n",
    "\n",
    "- Semantic similarity\n",
    "\n",
    "- Clustering and retrieval\n",
    "\n",
    "- High-quality downstream ML features\n",
    "\n",
    "This notebook treats embeddings as general-purpose semantic signals.\n",
    "\n",
    "## Why Sentence Transformers Matter\n",
    "\n",
    "Earlier methods:\n",
    "\n",
    "- BoW / TF-IDF → sparse, lexical\n",
    "\n",
    "- Word2Vec / GloVe → static, word-level\n",
    "\n",
    "- Doc2Vec → weak contextual modeling\n",
    "\n",
    "Sentence Transformers:\n",
    "\n",
    "- Encode full-sentence context\n",
    "\n",
    "- Handle polysemy and word order\n",
    "\n",
    "- Work well out-of-the-box\n",
    "\n",
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a69264-1b81-4a3b-8d4f-70c46d9b6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb86721-c678-4856-8196-b238792da9e5",
   "metadata": {},
   "source": [
    "Models are downloaded automatically on first use.\n",
    "\n",
    "# Load a Pre-Trained SBERT Model\n",
    "## Recommended Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2443c394-ebf2-40d5-94c7-622b3faf1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d1f86-d0bd-4889-935f-e7f9c6496a75",
   "metadata": {},
   "source": [
    "## Why this model?\n",
    "\n",
    "- Strong semantic performance\n",
    "\n",
    "- Lightweight (~384 dims)\n",
    "\n",
    "- Fast inference\n",
    "\n",
    "- Good production default\n",
    "\n",
    "# Example Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f5518f-3f49-4aa1-991a-5d2bfbf5a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"This model works very well\",\n",
    "    \"The system shows excellent performance\",\n",
    "    \"Terrible results and poor accuracy\",\n",
    "    \"The predictions are bad and unreliable\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2732394-9061-4204-9554-b48c4bad7a0e",
   "metadata": {},
   "source": [
    "# Generate Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2829b8-7090-4e4c-9d96-3a30e6d2a8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 384)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.encode(\n",
    "    sentences,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4297751-8de6-46cb-a74d-440290340e5f",
   "metadata": {},
   "source": [
    "# Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd867077-6ada-40a7-8322-ee5d5997a08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999999 , 0.5054958 , 0.2634276 , 0.13862145],\n",
       "       [0.5054958 , 1.        , 0.40614137, 0.2123204 ],\n",
       "       [0.2634276 , 0.40614137, 0.9999996 , 0.47412014],\n",
       "       [0.13862145, 0.2123204 , 0.47412014, 0.99999994]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb15e4-d661-487a-82e8-8283253d8bd3",
   "metadata": {},
   "source": [
    "## Interpret Similarity Matrix\n",
    "\n",
    "- High similarity → semantic closeness\n",
    "\n",
    "- Robust to synonym choice\n",
    "\n",
    "- Context-aware\n",
    "\n",
    "## Sentence Retrieval Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16629c0b-765f-4176-85ed-879df024d156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terrible results and poor accuracy</td>\n",
       "      <td>0.508541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The system shows excellent performance</td>\n",
       "      <td>0.438835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This model works very well</td>\n",
       "      <td>0.402197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The predictions are bad and unreliable</td>\n",
       "      <td>0.329885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence  similarity\n",
       "2      Terrible results and poor accuracy    0.508541\n",
       "1  The system shows excellent performance    0.438835\n",
       "0              This model works very well    0.402197\n",
       "3  The predictions are bad and unreliable    0.329885"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"poor model performance\"\n",
    "\n",
    "query_embedding = model.encode(\n",
    "    query,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "scores = cosine_similarity(\n",
    "    query_embedding.reshape(1, -1),\n",
    "    embeddings\n",
    ")[0]\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"sentence\": sentences,\n",
    "    \"similarity\": scores\n",
    "}).sort_values(\"similarity\", ascending=False)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ad14c-1d9f-453a-8a07-6a3fe6c2ec6d",
   "metadata": {},
   "source": [
    "# Document-Level Embeddings\n",
    "\n",
    "SBERT can encode:\n",
    "\n",
    "- Sentences\n",
    "- Paragraphs\n",
    "- Short documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7049b39c-486f-4eee-b5c1-af313f94ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Clean text improves machine learning models.\",\n",
    "    \"Tree-based models often struggle with sparse NLP features.\",\n",
    "    \"Transformers capture semantic meaning effectively.\"\n",
    "]\n",
    "\n",
    "doc_embeddings = model.encode(\n",
    "    documents,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073a3d8-3836-4bfc-9778-41aa3a00b5fc",
   "metadata": {},
   "source": [
    "## Clustering Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07a9b169-d63c-4335-a979-e2e591d32c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clean text improves machine learning models.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tree-based models often struggle with sparse N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers capture semantic meaning effectiv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  cluster\n",
       "0       Clean text improves machine learning models.        0\n",
       "1  Tree-based models often struggle with sparse N...        0\n",
       "2  Transformers capture semantic meaning effectiv...        1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "clusters = kmeans.fit_predict(doc_embeddings)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"document\": documents,\n",
    "    \"cluster\": clusters\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4192bed-7402-4d1c-9134-1a98218bf3b0",
   "metadata": {},
   "source": [
    "# Using SBERT Embeddings for Classification\n",
    "## Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b1b3f59-71de-426c-9b3b-16eb9ed881f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embeddings\n",
    "y = np.array([1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a841f413-3a51-4d12-aef0-ee0d82a610e2",
   "metadata": {},
   "source": [
    "## Train a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f9da494-fd08-4437-858c-158cc1af7938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.score(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac9c72d-dfef-4345-876f-3fedab1c5819",
   "metadata": {},
   "source": [
    "# Why Normalize Embeddings?\n",
    "\n",
    "- Cosine similarity assumes unit vectors\n",
    "- Stabilizes downstream ML\n",
    "- Improves clustering behavior\n",
    "- \n",
    "# Performance and Cost Considerations\n",
    "| Aspect            | SBERT           |\n",
    "| ----------------- | --------------- |\n",
    "| Quality           | Very high       |\n",
    "| Inference speed   | Medium          |\n",
    "| Memory            | Moderate        |\n",
    "| Training required | None (baseline) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c3e4b-cbdf-4b3b-9adf-b268a1fb744e",
   "metadata": {},
   "source": [
    "# When Sentence Transformers Are the Best Choice\n",
    "\n",
    "- `[ok] -` Semantic similarity\n",
    "- `[ok] -` Search / retrieval\n",
    "- `[ok] -` Clustering\n",
    "- `[ok] -` Low-label regimes\n",
    "- `[ok] -` Production-ready NLP\n",
    "\n",
    "# When They May Be Overkill\n",
    "\n",
    "- `[neg] -` Simple keyword tasks\n",
    "- `[neg] -` Extreme latency constraints\n",
    "- `[neg] -` Highly domain-specific jargon (without fine-tuning)\n",
    "\n",
    "- `[neg] -` Common Mistakes\n",
    "\n",
    "- `[neg] -` Treating SBERT as a classifier\n",
    "- `[neg] -` Forgetting normalization\n",
    "- `[neg] -` Using huge models unnecessarily\n",
    "- `[neg] -` Fine-tuning without enough data\n",
    "\n",
    "# Key Takeaways\n",
    "\n",
    "- Sentence Transformers are the modern default\n",
    "- They produce high-quality semantic embeddings\n",
    "- Minimal preprocessing required\n",
    "- Excellent balance of performance and usability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c7ea9-0663-4801-801b-1e5a356ac9ad",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
