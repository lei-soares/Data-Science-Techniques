{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac46153-4841-447c-ad1b-6c84424bb8a6",
   "metadata": {},
   "source": [
    "# Document Embeddings with Doc2Vec\n",
    "## Objective\n",
    "\n",
    "Learn fixed-length document embeddings directly from text using Doc2Vec, avoiding manual aggregation of word vectors.\n",
    "\n",
    "This notebook focuses on:\n",
    "\n",
    "- Document-level semantic representation\n",
    "\n",
    "- Similarity, clustering, and downstream ML usage\n",
    "\n",
    "- Proper training and evaluation discipline\n",
    "\n",
    "## Why Doc2Vec Exists\n",
    "\n",
    "Word embeddings require heuristic aggregation (mean, TF-IDF weighting).\n",
    "\n",
    "Doc2Vec instead:\n",
    "\n",
    "- Learns document vectors jointly with word vectors\n",
    "\n",
    "- Encodes document-level semantics directly\n",
    "\n",
    "- Produces dense, fixed-size representations\n",
    "\n",
    "## Doc2Vec Architectures (Conceptual)\n",
    "| Variant | Description                            |\n",
    "| ------- | -------------------------------------- |\n",
    "| PV-DM   | Distributed Memory (context + doc id)  |\n",
    "| PV-DBOW | Distributed Bag of Words (doc → words) |\n",
    "\n",
    "\n",
    "In practice:\n",
    "\n",
    "- PV-DBOW is faster and often stronger\n",
    "\n",
    "- PV-DM can help with word order (limited)\n",
    "\n",
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7896f0b0-f7b0-4806-82b4-b6ca9bbf5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f80459-b721-4fc7-931b-bb69c623705e",
   "metadata": {},
   "source": [
    "# Example Corpus\n",
    "\n",
    "We use **tokenized, normalized documents.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a668c3e-2db3-4037-9d5d-603e7cd6e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    [\"clean\", \"text\", \"better\", \"model\"],\n",
    "    [\"terrible\", \"result\", \"poor\", \"performance\"],\n",
    "    [\"robust\", \"interpretable\", \"model\"],\n",
    "    [\"bad\", \"prediction\", \"weak\", \"accuracy\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d745164e-9e7b-4066-95c7-7540a4354b9d",
   "metadata": {},
   "source": [
    "# Tag Documents\n",
    "\n",
    "Doc2Vec requires unique document IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10210e6c-75ca-4e8c-9dd2-039e280fe1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_docs = [\n",
    "    TaggedDocument(words=doc, tags=[f\"DOC_{i}\"])\n",
    "    for i, doc in enumerate(documents)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcc62b-8f19-4bd0-b8e7-0f65002a34e6",
   "metadata": {},
   "source": [
    "# Train a Doc2Vec Model\n",
    "## Baseline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d4dce78-83af-47b9-b867-883a23d0e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    epochs=40,\n",
    "    dm=0  # PV-DBOW\n",
    ")\n",
    "\n",
    "doc2vec_model.build_vocab(tagged_docs)\n",
    "doc2vec_model.train(\n",
    "    tagged_docs,\n",
    "    total_examples=doc2vec_model.corpus_count,\n",
    "    epochs=doc2vec_model.epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d7a15e-bbbb-4e9f-bc0a-dd098c525b7f",
   "metadata": {},
   "source": [
    "## Inspect Learned Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dae59e91-ee11-40d6-b844-b4c388a5ec6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectors = np.vstack([\n",
    "    doc2vec_model.dv[tag]\n",
    "    for tag in doc2vec_model.dv.index_to_key\n",
    "])\n",
    "\n",
    "doc_vectors.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62256707-1a25-48de-9380-b49916a440c2",
   "metadata": {},
   "source": [
    "## Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8bba05d-0f9e-4cc6-98d7-b24ab18c9328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000001 ,  0.18371744,  0.01432705,  0.00617551],\n",
       "       [ 0.18371744,  0.99999994, -0.04312898,  0.17653593],\n",
       "       [ 0.01432705, -0.04312898,  0.9999999 ,  0.02648791],\n",
       "       [ 0.00617551,  0.17653593,  0.02648791,  0.99999976]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(doc_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dce061-8662-4008-9cf9-358bce0cc40b",
   "metadata": {},
   "source": [
    "# Infer Vector for Unseen Document\n",
    "\n",
    "**Important**: Inference ≠ training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b56c22a6-a967-4995-8acd-dd391f3fccc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = [\"clean\", \"interpretable\", \"model\"]\n",
    "\n",
    "inferred_vector = doc2vec_model.infer_vector(\n",
    "    new_doc,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "inferred_vector.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50ce34-6a7f-4991-9974-8838e2b74a73",
   "metadata": {},
   "source": [
    "# Similarity to Training Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e91935d7-61f8-4eaa-a07a-7d96f1cb2a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03518941, -0.12601991, -0.03049923, -0.01644303]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = cosine_similarity(\n",
    "    inferred_vector.reshape(1, -1),\n",
    "    doc_vectors\n",
    ")\n",
    "\n",
    "similarities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7eb07-d173-47bd-99d9-b449af678d01",
   "metadata": {},
   "source": [
    "# Downstream Use: Classification Example\n",
    "## Build Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87431881-85c9-4c80-9618-a0b9f8c8b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = doc_vectors\n",
    "y = np.array([1, 0, 1, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e5460-6fa9-4bb4-89c4-e7b99c083781",
   "metadata": {},
   "source": [
    "## Train a Simple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88bed45a-60ba-420a-baa7-a6aa01400fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.score(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de20ab0-7401-4c76-880e-983ab6fe441a",
   "metadata": {},
   "source": [
    "# TF-IDF Weighted Doc2Vec (Advanced)\n",
    "## Motivation\n",
    "\n",
    "- Standard Doc2Vec treats all words equally\n",
    "\n",
    "- TF-IDF weighting can bias learning toward informative terms\n",
    "\n",
    "⚠️ This is non-standard and task-dependent.\n",
    "\n",
    "# Key Limitations of Doc2Vec\n",
    "\n",
    "- Sensitive to hyperparameters\n",
    "\n",
    "- Requires sufficient data\n",
    "\n",
    "- Less effective on short texts\n",
    "\n",
    "- Often outperformed by Sentence-BERT\n",
    "\n",
    "# When Doc2Vec Makes Sense\n",
    "\n",
    "- `[ok] -` Medium-sized corpora\n",
    "- `[ok] -` Document similarity and clustering\n",
    "- `[ok] -` Memory-constrained environments\n",
    "- `[ok] -` As a bridge between classical and modern NLP\n",
    "\n",
    "# When NOT to Use Doc2Vec\n",
    "\n",
    "- `[neg] -` Very small datasets\n",
    "- `[neg] -` Highly contextual language\n",
    "- `[neg] -` Sentence-level semantics\n",
    "- `[neg] -` When transformer embeddings are available\n",
    "\n",
    "# Common Mistakes\n",
    "\n",
    "- `[neg] -` Training on tiny datasets\n",
    "- `[neg] -` Comparing inferred and trained vectors unfairly\n",
    "- `[neg] -` Ignoring randomness (seed control)\n",
    "- `[neg] -` Treating Doc2Vec as state-of-the-art\n",
    "\n",
    "# Key Takeaways\n",
    "\n",
    "- Doc2Vec learns document-level representations\n",
    "\n",
    "- It removes aggregation heuristics\n",
    "\n",
    "- Performance depends heavily on data size\n",
    "\n",
    "- Modern transformers usually dominate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683a3e6-86aa-4ae7-8aa8-d9b6cfbd8d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a7d99e7-1d92-4804-be1a-d38ff4b07eaf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
