{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d2948a-32f0-4359-a8b8-c40aa7e8fffc",
   "metadata": {},
   "source": [
    "# Tree-Based Models for Text Data\n",
    "## Objective\n",
    "\n",
    "Evaluate the use of tree-based models on text data represented via BoW / TF-IDF, and understand:\n",
    "\n",
    "- When they work\n",
    "\n",
    "- When they fail\n",
    "\n",
    "- How to mitigate known limitations\n",
    "\n",
    "> This notebook emphasizes diagnostic insight over raw performance.\n",
    "\n",
    "## Why This Notebook Exists\n",
    "\n",
    "Tree-based models are powerful for:\n",
    "\n",
    "- Tabular data\n",
    "\n",
    "- Non-linear interactions\n",
    "\n",
    "- Feature selection\n",
    "\n",
    "However, text features are:\n",
    "\n",
    "- High-dimensional\n",
    "\n",
    "- Sparse\n",
    "\n",
    "- Weakly correlated\n",
    "\n",
    "This creates a structural mismatch.\n",
    "\n",
    "Understanding this mismatch prevents:\n",
    "\n",
    "- Wasted compute\n",
    "\n",
    "- Overfitting\n",
    "\n",
    "- Misleading benchmarks\n",
    "\n",
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f35be0-8360-4841-8fa9-948f1c5db510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d29e7-8512-401f-aaa9-ce6ce795fcfd",
   "metadata": {},
   "source": [
    "# Example Dataset\n",
    "\n",
    "Same binary classification setup used for linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06abda7a-47a1-4926-81b7-d51cfb510e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"text\": [\n",
    "        \"this model works well\",\n",
    "        \"terrible results and poor model\",\n",
    "        \"excellent performance and stability\",\n",
    "        \"bad predictions and weak accuracy\",\n",
    "        \"robust and interpretable model\",\n",
    "        \"awful behavior and unreliable output\"\n",
    "    ],\n",
    "    \"label\": [1, 0, 1, 0, 1, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c335d9-59ba-4e67-909a-b2a8d8e91925",
   "metadata": {},
   "source": [
    "# Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db6f28d-2e62-4a12-a4d5-c431d5885654",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"],\n",
    "    df[\"label\"],\n",
    "    test_size=0.3,\n",
    "    random_state=2010,\n",
    "    stratify=df[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba495f-ed5a-433f-a059-6f08948fc765",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "Why Try It?\n",
    "\n",
    "- Acts as a diagnostic baseline\n",
    "\n",
    "- Highlights sparsity issues immediately\n",
    "\n",
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "237f7e64-d4c4-48c7-a649-c69536da3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=100)),\n",
    "    (\"model\", DecisionTreeClassifier(\n",
    "        max_depth=5,\n",
    "        random_state=2010\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0219807-96eb-49ad-a872-14b97b2c939f",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "273acde7-dbef-425e-b9bf-45ae6e1d2c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9774e4a-6e0c-4ee0-8013-b058a165fe4a",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "## Why Random Forest?\n",
    "\n",
    "- Ensemble reduces variance\n",
    "\n",
    "- Implicit feature selection\n",
    "\n",
    "But:\n",
    "\n",
    "- Memory-intensive\n",
    "\n",
    "- Still struggles with sparse signals\n",
    "\n",
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c23c9d0a-2d4e-46dd-8467-2bfe5bc3c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=200)),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        random_state=2010,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15302b-74c5-472c-8615-6d34d7393742",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e354ef1a-68cf-4a83-ae00-754b3f92ead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pantu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pantu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\pantu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efd075-18e9-4338-b3f5-d9bd04cf507e",
   "metadata": {},
   "source": [
    "# Gradient Boosting\n",
    "## Why Gradient Boosting?\n",
    "\n",
    "- Sequential error correction\n",
    "\n",
    "- Can sometimes extract signal from noisy features\n",
    "\n",
    "Limitation:\n",
    "\n",
    "- Requires dense input â†’ implicit densification\n",
    "\n",
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1899eedf-ba89-4495-ba36-1280922f23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=100)),\n",
    "    (\"model\", GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=2010\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce497e6-d2b6-4b53-8496-338f6b874fca",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54873907-3bc3-47b6-8906-4280946a79ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       1.0\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509e3c0-c01a-48c9-ad34-e45b6288e72b",
   "metadata": {},
   "source": [
    "# Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e517ddc7-cda7-4244-a50b-ad33c829bc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy\n",
       "0      Decision Tree       0.0\n",
       "1      Random Forest       0.5\n",
       "2  Gradient Boosting       0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"model\": [\n",
    "        \"Decision Tree\",\n",
    "        \"Random Forest\",\n",
    "        \"Gradient Boosting\"\n",
    "    ],\n",
    "    \"accuracy\": [\n",
    "        accuracy_score(y_test, y_pred_dt),\n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_gb)\n",
    "    ]\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52dfbaa-2e6b-499c-ad1a-b13bd295e644",
   "metadata": {},
   "source": [
    "# Feature Importance Caveats\n",
    "\n",
    "Tree-based feature importance on text:\n",
    "\n",
    "- Biased toward high-frequency tokens\n",
    "\n",
    "- Unstable across runs\n",
    "\n",
    "- Hard to interpret semantically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34c6c5b2-3dc7-414f-832a-da60dc294837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0.16479400749063672\n",
      "and 0.12921348314606745\n",
      "output 0.08801498127340825\n",
      "this 0.08052434456928839\n",
      "robust 0.0702247191011236\n",
      "weak 0.06367041198501872\n",
      "predictions 0.055867665418227214\n",
      "well 0.0552434456928839\n",
      "bad 0.047752808988764044\n",
      "awful 0.04681647940074907\n"
     ]
    }
   ],
   "source": [
    "rf_model = rf_pipeline.named_steps[\"model\"]\n",
    "vectorizer = rf_pipeline.named_steps[\"tfidf\"]\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "top_features = np.argsort(importances)[-10:]\n",
    "\n",
    "for idx in reversed(top_features):\n",
    "    print(feature_names[idx], importances[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95785e2-8c0a-4dd4-aa02-585d911e924e",
   "metadata": {},
   "source": [
    "# Key Lessons Learned\n",
    "\n",
    "- Trees are not text-native models\n",
    "\n",
    "- Sparsity kills split quality\n",
    "\n",
    "- Linear models dominate in classical NLP\n",
    "\n",
    "Trees shine when text is:\n",
    "\n",
    "- Heavily engineered\n",
    "\n",
    "- Reduced to dense representations\n",
    "\n",
    "# When Tree-Based Models DO Make Sense\n",
    "\n",
    "- `[ok] - ` TF-IDF + dimensionality reduction\n",
    "- `[ok] - ` Text-derived numerical features\n",
    "- `[ok] - ` Embeddings (dense vectors)\n",
    "- `[ok] - ` Hybrid tabular + NLP models\n",
    "\n",
    "# Common Mistakes\n",
    "\n",
    "- `[x]` - Blindly applying Random Forests to raw TF-IDF\n",
    "\n",
    "- `[x]` - Ignoring memory usage\n",
    "\n",
    "- `[x]` - Over-tuning weak model classes\n",
    "\n",
    "- `[x]` - Misreading feature importance\n",
    "\n",
    "\n",
    "# Key Takeaways\n",
    "\n",
    "- Tree-based models are diagnostic, not default, for text\n",
    "\n",
    "- Sparsity vs split logic is the core conflict\n",
    "\n",
    "- Use trees after representation engineering\n",
    "\n",
    "- Always benchmark against linear baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89411864-b45d-446b-a704-273e86883c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883244c-a6dd-44d1-b2e0-1f0375224d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
